{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test 3 ecoc resnet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "450ba63f84e84b6397938d7e42063cc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6ca246d083754ace8957e4e5833c1dbc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_be7051bcbfa54d73a469b3f0a512ac11",
              "IPY_MODEL_1a91a7a4b6c54c0e99c57a1a72f799ee"
            ]
          }
        },
        "6ca246d083754ace8957e4e5833c1dbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "be7051bcbfa54d73a469b3f0a512ac11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_87ce7c730a454fc7a94ba72f1285510f",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55bccbce26114dc2899beb316dd292b0"
          }
        },
        "1a91a7a4b6c54c0e99c57a1a72f799ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ad698d56dc2d4e45bddefd1ec038f5a9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 110MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ec982a47628744ba8b59905855a7ebc1"
          }
        },
        "87ce7c730a454fc7a94ba72f1285510f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55bccbce26114dc2899beb316dd292b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ad698d56dc2d4e45bddefd1ec038f5a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ec982a47628744ba8b59905855a7ebc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9ghzwkh8rFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!tar -xzf \"/content/drive/My Drive/3/1.tar.gz\" -C /content"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy1NsLQ5YdvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from typing import List\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import time\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjwZ0IXn8tG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ecoc_classifier(ClassifierMixin, BaseEstimator):\n",
        "\n",
        "    def __init__(self, model_constructer=None, ecoc_matrix=None, model_list=None, code_word_length=0):\n",
        "        '''\n",
        "        a slightly moddified version of my ecoc model specific to this test\n",
        "\n",
        "        '''\n",
        "        self.model_constructer = model_constructer\n",
        "        self.ecoc_matrix = ecoc_matrix\n",
        "        self.model_list = model_list\n",
        "        self.code_word_length = code_word_length\n",
        "\n",
        "    def Hdistance(self, model_output : List , code_word : List ):# determins hamming distance\n",
        "\n",
        "        '''\n",
        "        counts the  diffrance in bits\n",
        "        '''\n",
        "\n",
        "        distance = 0\n",
        "        pos = 0\n",
        "        while(pos < self.code_word_length):\n",
        "\n",
        "            if( int(model_output[pos]) !=  code_word[pos] ):\n",
        "\n",
        "                distance += 1\n",
        "\n",
        "            pos += 1\n",
        "\n",
        "        return distance\n",
        "\n",
        "    def determinLable(self, results):\n",
        "\n",
        "        '''\n",
        "        when given an list of output codes from the models, this assigns a list\n",
        "        of code words from the ecoc matrix which are the smallest hamming distance\n",
        "        '''\n",
        "\n",
        "        output = np.empty( ( results.shape[0], self.code_word_length ) )\n",
        "\n",
        "        item = 0\n",
        "        while(item < results.shape[0]):\n",
        "\n",
        "            smallest_distance = -1\n",
        "\n",
        "            for code_word in self.ecoc_matrix :\n",
        "\n",
        "                distance = self.Hdistance(results[item], code_word)\n",
        "\n",
        "                if( distance < smallest_distance or smallest_distance == -1):\n",
        "\n",
        "                    smallest_distance = distance\n",
        "                    output_code = code_word\n",
        "\n",
        "            output[item] = np.array(output_code, copy=True)\n",
        "            item += 1\n",
        "\n",
        "        return output\n",
        "\n",
        "    def fit(self, X, y, **kwargs):\n",
        "\n",
        "        self.code_word_length = len(self.ecoc_matrix[0])\n",
        "\n",
        "        '''\n",
        "        a standerd implementation of fit used by all sklearn models\n",
        "\n",
        "        in this case it initalzes a model for each column of the ecoc matrix,\n",
        "        and then calls fit to train it on the bits of the column. after wards the\n",
        "        model is append to a list for latter use\n",
        "        '''\n",
        "\n",
        "        self.classes_ = unique_labels(y)\n",
        "\n",
        "        self.X_ = X\n",
        "        self.y_ = y\n",
        "\n",
        "        if(self.model_list == None):\n",
        "\n",
        "            self.model_list = []\n",
        "\n",
        "            if(self.model_constructer != None):\n",
        "\n",
        "                bit_pos = 0\n",
        "                while(bit_pos < self.code_word_length):\n",
        "\n",
        "                    self.model_list.append(self.model_constructer())\n",
        "                    bit_pos += 1\n",
        "\n",
        "            kwargs['column'] = None\n",
        "\n",
        "            bit_pos = 0\n",
        "            while(bit_pos < self.code_word_length):\n",
        "\n",
        "                kwargs['column'] = bit_pos\n",
        "\n",
        "                self.model_list[bit_pos].fit(np.load(\"/content/1/images_{}.npy\".format(bit_pos)).swapaxes(1,3).astype(np.float32), np.load(\"/content/1/lables_{}.npy\".format(bit_pos)).astype(np.float32), **kwargs)\n",
        "                bit_pos += 1\n",
        "\n",
        "        # Return the classifier\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, y=None):\n",
        "\n",
        "        '''\n",
        "        a standerd implementation of the predict function used by all sklearn models.\n",
        "\n",
        "        here after checking if the data is vailid it is feed into each model of the list, and a new output code\n",
        "        is made from the outputs which is then check against the ecoc matrix to see which row the new code word\n",
        "        is closest to.\n",
        "        '''\n",
        "\n",
        "        # Check is fit had been called\n",
        "        check_is_fitted(self, ['X_', 'y_'])\n",
        "\n",
        "        print('predicting')\n",
        "\n",
        "        results = np.empty((self.code_word_length,) + (X.shape[0],) + (1,))\n",
        "\n",
        "        pos = 0;\n",
        "        for model in self.model_list:\n",
        "\n",
        "            results[pos] = model.predict( X ).cpu().numpy()\n",
        "            pos += 1\n",
        "\n",
        "        results = results.reshape((self.code_word_length, X.shape[0])).T.round()\n",
        "\n",
        "        global output_array\n",
        "        output_array = results\n",
        "\n",
        "        return self.determinLable(results)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        results = self.predict(X)\n",
        "        right = 0\n",
        "\n",
        "        pos = 0\n",
        "        for sample in results:\n",
        "\n",
        "            if (sample == y[pos]).all():\n",
        "\n",
        "                right += 1\n",
        "\n",
        "\n",
        "            pos += 1\n",
        "\n",
        "        return right/X.shape[0]"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m56Nxpy8YHKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Main_Model(nn.Module):\n",
        "\n",
        "    '''\n",
        "    a pytorch binary classifier \n",
        "    '''\n",
        "\n",
        "    device = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        super(Main_Model,self).__init__()\n",
        "\n",
        "        eye = models.resnet18(pretrained=True)\n",
        "        eye.require_grad = False\n",
        "        eye_out = eye.fc.out_features\n",
        "        self.prams = nn.ModuleList([eye,\n",
        "                                    nn.Linear(eye_out,64),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(64,10),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(10,1),\n",
        "                                    ]).to(self.device)\n",
        "    def forward(self,x):\n",
        "\n",
        "        for mod in self.prams:\n",
        "            x = mod(x)\n",
        "        return x\n",
        "\n",
        "    def fit(self,X, y, batch_size, epochs, column):\n",
        "        self.prams.train(True)\n",
        "        train_set = torch.utils.data.TensorDataset(torch.tensor(X),torch.tensor(y))\n",
        "        train_set = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
        "        optimizer = torch.optim.Adam(self.prams.parameters(), lr=0.0001)\n",
        "        lr_schedular = torch.optim.lr_scheduler.StepLR(optimizer, 5)\n",
        "        loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        #loss_fn = nn.CrossEntropyLoss()\n",
        "        pos = 0\n",
        "        total_time = 0\n",
        "        while( pos < epochs):\n",
        "            start_time = time.time()\n",
        "            running_loss = 0\n",
        "            for image_batch, label_batch in iter(train_set):\n",
        "                image_batch, label_batch = image_batch.to(self.device), label_batch.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(image_batch)\n",
        "                loss = loss_fn(torch.flatten(outputs),label_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss\n",
        "\n",
        "            epoch_time = (time.time() - start_time)\n",
        "            print(\"-{}/{}\".format(pos+1,epochs),\"train time:\", epoch_time,\"loss total:\", running_loss.item())\n",
        "            accuracy = self.eval(test_images, test_lables, 500, column)\n",
        "            lr_schedular.step()\n",
        "            total_time += epoch_time\n",
        "\n",
        "            pos += 1\n",
        "\n",
        "        global accuracy_array\n",
        "        accuracy_array.append(accuracy)\n",
        "        global time_totals\n",
        "        time_totals.append(total_time)        \n",
        "\n",
        "    def predict(self,X):\n",
        "\n",
        "      X = torch.tensor(X, device=self.device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output = self(X)\n",
        "\n",
        "          return torch.sigmoid(output).round()\n",
        "\n",
        "    def eval(self,X, y, batch_size, column):\n",
        "        self.prams.train(False)\n",
        "        test_set = torch.utils.data.TensorDataset(torch.tensor(X),torch.tensor(y))\n",
        "        test_set = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "        right = 0\n",
        "\n",
        "        for image_batch, label_batch in iter(test_set):\n",
        "            image_batch, label_batch = image_batch.to(self.device), label_batch.to(self.device)[:,column].unsqueeze(1)\n",
        "            output_batch = self.predict(image_batch)\n",
        "            right += (output_batch == label_batch).sum().item()\n",
        "            \n",
        "        after = (right/y.shape[0])\n",
        "        print(\"after: \", after)\n",
        "        return after\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37FXVTxny4pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "training_images = []\n",
        "training_lables = []\n",
        "\n",
        "general_file_name = \"3__1_80_\"\n",
        "\n",
        "test_images = np.load(\"/content/drive/My Drive/1/{}/test_images.npy\".format(general_file_name[3])).swapaxes(1,3).astype(np.float32)\n",
        "test_lables = np.load(\"/content/drive/My Drive/1/{}/test_lables.npy\".format(general_file_name[3])).astype(np.int64)\n",
        "\n",
        "ecoc_matrix = np.loadtxt(\"/content/drive/My Drive/10x10\", delimiter=',')\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cR6VQkiUztn0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "450ba63f84e84b6397938d7e42063cc7",
            "6ca246d083754ace8957e4e5833c1dbc",
            "be7051bcbfa54d73a469b3f0a512ac11",
            "1a91a7a4b6c54c0e99c57a1a72f799ee",
            "87ce7c730a454fc7a94ba72f1285510f",
            "55bccbce26114dc2899beb316dd292b0",
            "ad698d56dc2d4e45bddefd1ec038f5a9",
            "ec982a47628744ba8b59905855a7ebc1"
          ]
        },
        "outputId": "b19f63e3-d129-4abd-960f-f944fa10a082"
      },
      "source": [
        "\n",
        "main_model = ecoc_classifier(Main_Model, ecoc_matrix=ecoc_matrix)\n",
        "\n",
        "batch_size = 64\n",
        "epochs=10\n",
        "\n",
        "output_array = []\n",
        "\n",
        "accuracy_array = []\n",
        "\n",
        "time_totals = []\n",
        "\n",
        "average_time = np.vectorize(lambda x : x/epochs)\n",
        "\n",
        "main_model.fit(training_images, training_lables, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "print(main_model.score(test_images, test_lables))\n",
        "\n",
        "np.save('/content/drive/My Drive/{}_accuracy_array'.format(general_file_name), np.array(accuracy_array))\n",
        "np.save('/content/drive/My Drive/{}_output_array'.format(general_file_name), output_array)\n",
        "np.save('/content/drive/My Drive/{}_total_times'.format(general_file_name), np.array(time_totals))\n",
        "np.save('/content/drive/My Drive/{}_average_times'.format(general_file_name), average_time(time_totals))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "450ba63f84e84b6397938d7e42063cc7",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-1/10 train time: 14.950243473052979 loss total: 183.59376525878906\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "after:  0.88535\n",
            "-2/10 train time: 14.542763233184814 loss total: 141.76185607910156\n",
            "after:  0.8928\n",
            "-3/10 train time: 14.60327672958374 loss total: 111.05323791503906\n",
            "after:  0.9036\n",
            "-4/10 train time: 14.7224702835083 loss total: 87.03898620605469\n",
            "after:  0.9126\n",
            "-5/10 train time: 14.803403377532959 loss total: 74.90347290039062\n",
            "after:  0.91095\n",
            "-6/10 train time: 14.908115863800049 loss total: 37.36863327026367\n",
            "after:  0.9412\n",
            "-7/10 train time: 14.932056188583374 loss total: 22.147886276245117\n",
            "after:  0.94535\n",
            "-8/10 train time: 14.945264101028442 loss total: 12.21973705291748\n",
            "after:  0.94855\n",
            "-9/10 train time: 14.96649980545044 loss total: 5.768491744995117\n",
            "after:  0.9499\n",
            "-10/10 train time: 15.01505184173584 loss total: 2.5858089923858643\n",
            "after:  0.9502\n",
            "-1/10 train time: 15.343553304672241 loss total: 213.77342224121094\n",
            "after:  0.8658\n",
            "-2/10 train time: 15.21350884437561 loss total: 161.9730224609375\n",
            "after:  0.8645\n",
            "-3/10 train time: 15.245881080627441 loss total: 129.16282653808594\n",
            "after:  0.87185\n",
            "-4/10 train time: 15.304155588150024 loss total: 101.96107482910156\n",
            "after:  0.88415\n",
            "-5/10 train time: 15.334933757781982 loss total: 88.3051528930664\n",
            "after:  0.89935\n",
            "-6/10 train time: 15.393538236618042 loss total: 52.88458251953125\n",
            "after:  0.92835\n",
            "-7/10 train time: 15.43805718421936 loss total: 33.2454833984375\n",
            "after:  0.93295\n",
            "-8/10 train time: 15.427603244781494 loss total: 20.66433334350586\n",
            "after:  0.93855\n",
            "-9/10 train time: 15.413123369216919 loss total: 10.978988647460938\n",
            "after:  0.94065\n",
            "-10/10 train time: 15.440613985061646 loss total: 5.2556257247924805\n",
            "after:  0.9416\n",
            "-1/10 train time: 15.60758924484253 loss total: 127.86713409423828\n",
            "after:  0.94175\n",
            "-2/10 train time: 15.365147590637207 loss total: 82.54785919189453\n",
            "after:  0.9453\n",
            "-3/10 train time: 15.409423351287842 loss total: 59.31391906738281\n",
            "after:  0.94595\n",
            "-4/10 train time: 15.435235500335693 loss total: 45.89474105834961\n",
            "after:  0.95515\n",
            "-5/10 train time: 15.444631576538086 loss total: 38.36771774291992\n",
            "after:  0.95665\n",
            "-6/10 train time: 15.463349103927612 loss total: 14.898592948913574\n",
            "after:  0.97405\n",
            "-7/10 train time: 15.477869987487793 loss total: 6.765717029571533\n",
            "after:  0.9758\n",
            "-8/10 train time: 15.440447330474854 loss total: 3.293919324874878\n",
            "after:  0.97605\n",
            "-9/10 train time: 15.467622756958008 loss total: 1.5222002267837524\n",
            "after:  0.9766\n",
            "-10/10 train time: 15.49465560913086 loss total: 0.774858832359314\n",
            "after:  0.97615\n",
            "-1/10 train time: 15.516586542129517 loss total: 226.05030822753906\n",
            "after:  0.8775\n",
            "-2/10 train time: 15.366253852844238 loss total: 159.82789611816406\n",
            "after:  0.85575\n",
            "-3/10 train time: 15.392483234405518 loss total: 120.5990219116211\n",
            "after:  0.8229\n",
            "-4/10 train time: 15.423223495483398 loss total: 97.14366149902344\n",
            "after:  0.8674\n",
            "-5/10 train time: 15.45609974861145 loss total: 76.84416198730469\n",
            "after:  0.9144\n",
            "-6/10 train time: 15.457188844680786 loss total: 36.6826171875\n",
            "after:  0.9403\n",
            "-7/10 train time: 15.457535743713379 loss total: 19.552553176879883\n",
            "after:  0.9451\n",
            "-8/10 train time: 15.434398889541626 loss total: 10.101539611816406\n",
            "after:  0.94735\n",
            "-9/10 train time: 15.408401727676392 loss total: 4.840401649475098\n",
            "after:  0.9469\n",
            "-10/10 train time: 15.374399185180664 loss total: 2.214508295059204\n",
            "after:  0.9473\n",
            "-1/10 train time: 15.518460512161255 loss total: 249.28590393066406\n",
            "after:  0.83495\n",
            "-2/10 train time: 15.338739395141602 loss total: 188.5081024169922\n",
            "after:  0.8492\n",
            "-3/10 train time: 15.402664422988892 loss total: 145.31312561035156\n",
            "after:  0.86305\n",
            "-4/10 train time: 15.478179693222046 loss total: 114.32616424560547\n",
            "after:  0.8607\n",
            "-5/10 train time: 15.499157667160034 loss total: 97.78141021728516\n",
            "after:  0.88295\n",
            "-6/10 train time: 15.548851728439331 loss total: 53.752037048339844\n",
            "after:  0.91905\n",
            "-7/10 train time: 15.539426326751709 loss total: 33.111732482910156\n",
            "after:  0.9248\n",
            "-8/10 train time: 15.53935170173645 loss total: 19.951549530029297\n",
            "after:  0.92645\n",
            "-9/10 train time: 15.550464630126953 loss total: 10.996661186218262\n",
            "after:  0.9284\n",
            "-10/10 train time: 15.55564546585083 loss total: 7.204113960266113\n",
            "after:  0.92675\n",
            "-1/10 train time: 15.582621097564697 loss total: 248.083740234375\n",
            "after:  0.8441\n",
            "-2/10 train time: 15.37029767036438 loss total: 183.39723205566406\n",
            "after:  0.85125\n",
            "-3/10 train time: 15.414684295654297 loss total: 143.54286193847656\n",
            "after:  0.85665\n",
            "-4/10 train time: 15.455867767333984 loss total: 115.4526596069336\n",
            "after:  0.88025\n",
            "-5/10 train time: 15.482515811920166 loss total: 96.458740234375\n",
            "after:  0.88165\n",
            "-6/10 train time: 15.492447853088379 loss total: 52.55360794067383\n",
            "after:  0.9189\n",
            "-7/10 train time: 15.501347303390503 loss total: 33.80331039428711\n",
            "after:  0.9244\n",
            "-8/10 train time: 15.49042272567749 loss total: 20.9107666015625\n",
            "after:  0.92945\n",
            "-9/10 train time: 15.5145103931427 loss total: 12.078530311584473\n",
            "after:  0.93135\n",
            "-10/10 train time: 15.532405614852905 loss total: 7.065521717071533\n",
            "after:  0.9314\n",
            "-1/10 train time: 15.557476997375488 loss total: 215.64718627929688\n",
            "after:  0.881\n",
            "-2/10 train time: 15.382707595825195 loss total: 149.04949951171875\n",
            "after:  0.86955\n",
            "-3/10 train time: 15.409459114074707 loss total: 112.47090911865234\n",
            "after:  0.876\n",
            "-4/10 train time: 15.458373785018921 loss total: 88.20104217529297\n",
            "after:  0.8923\n",
            "-5/10 train time: 15.473858833312988 loss total: 71.50637817382812\n",
            "after:  0.9232\n",
            "-6/10 train time: 15.521151542663574 loss total: 34.31988525390625\n",
            "after:  0.9432\n",
            "-7/10 train time: 15.527923583984375 loss total: 19.2266788482666\n",
            "after:  0.9475\n",
            "-8/10 train time: 15.536756753921509 loss total: 10.43420696258545\n",
            "after:  0.95\n",
            "-9/10 train time: 15.537117719650269 loss total: 4.747466087341309\n",
            "after:  0.9502\n",
            "-10/10 train time: 15.51333475112915 loss total: 1.980008840560913\n",
            "after:  0.95115\n",
            "-1/10 train time: 15.552014350891113 loss total: 214.20730590820312\n",
            "after:  0.8833\n",
            "-2/10 train time: 15.369561195373535 loss total: 154.06402587890625\n",
            "after:  0.88535\n",
            "-3/10 train time: 15.388174533843994 loss total: 115.43553161621094\n",
            "after:  0.90015\n",
            "-4/10 train time: 15.447603225708008 loss total: 89.96749114990234\n",
            "after:  0.90765\n",
            "-5/10 train time: 15.530139446258545 loss total: 75.51912689208984\n",
            "after:  0.8999\n",
            "-6/10 train time: 15.525977611541748 loss total: 38.45194625854492\n",
            "after:  0.94115\n",
            "-7/10 train time: 15.499865770339966 loss total: 21.540552139282227\n",
            "after:  0.9455\n",
            "-8/10 train time: 15.457106351852417 loss total: 11.846802711486816\n",
            "after:  0.9472\n",
            "-9/10 train time: 15.426632165908813 loss total: 6.2850751876831055\n",
            "after:  0.9484\n",
            "-10/10 train time: 15.375373601913452 loss total: 3.5550856590270996\n",
            "after:  0.94695\n",
            "-1/10 train time: 15.59426736831665 loss total: 249.02960205078125\n",
            "after:  0.84415\n",
            "-2/10 train time: 15.369173049926758 loss total: 188.95578002929688\n",
            "after:  0.85685\n",
            "-3/10 train time: 15.409935712814331 loss total: 148.75453186035156\n",
            "after:  0.86795\n",
            "-4/10 train time: 15.457811117172241 loss total: 116.43284606933594\n",
            "after:  0.88105\n",
            "-5/10 train time: 15.45354175567627 loss total: 95.46919250488281\n",
            "after:  0.8702\n",
            "-6/10 train time: 15.518683433532715 loss total: 55.257503509521484\n",
            "after:  0.9166\n",
            "-7/10 train time: 15.514877080917358 loss total: 31.511741638183594\n",
            "after:  0.92345\n",
            "-8/10 train time: 15.542537927627563 loss total: 17.522987365722656\n",
            "after:  0.9279\n",
            "-9/10 train time: 15.559594631195068 loss total: 8.587825775146484\n",
            "after:  0.9291\n",
            "-10/10 train time: 15.550162553787231 loss total: 4.622857570648193\n",
            "after:  0.9288\n",
            "-1/10 train time: 15.600749254226685 loss total: 257.9004821777344\n",
            "after:  0.83935\n",
            "-2/10 train time: 15.38032603263855 loss total: 192.943603515625\n",
            "after:  0.8481\n",
            "-3/10 train time: 15.434265375137329 loss total: 152.3011474609375\n",
            "after:  0.8525\n",
            "-4/10 train time: 15.467909336090088 loss total: 125.3700180053711\n",
            "after:  0.88135\n",
            "-5/10 train time: 15.501628637313843 loss total: 103.1165771484375\n",
            "after:  0.889\n",
            "-6/10 train time: 15.54442048072815 loss total: 62.0445556640625\n",
            "after:  0.9114\n",
            "-7/10 train time: 15.549980640411377 loss total: 41.10023498535156\n",
            "after:  0.9186\n",
            "-8/10 train time: 15.54197907447815 loss total: 26.606670379638672\n",
            "after:  0.92375\n",
            "-9/10 train time: 15.548120021820068 loss total: 15.921845436096191\n",
            "after:  0.92625\n",
            "-10/10 train time: 15.51388168334961 loss total: 9.381296157836914\n",
            "after:  0.92725\n",
            "predicting\n",
            "0.92255\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}