{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test 2 ecoc resnet",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd065ff4daaf4cd4a003ef79fc9c4bf1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_69c374f0f74541bba0ff4c937c6d2a54",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eee99ad8546946a2b422d0f04686c048",
              "IPY_MODEL_b91bf300d51d4c3e9638690f680d1781"
            ]
          }
        },
        "69c374f0f74541bba0ff4c937c6d2a54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eee99ad8546946a2b422d0f04686c048": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_80f6cea6a4394edb9f761e8a7859eaf4",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bd844c747d14740b765fba904b6c6f1"
          }
        },
        "b91bf300d51d4c3e9638690f680d1781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f56cd22dbe5e49aba7fc705ac6fd39dc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:11&lt;00:00, 4.08MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6f333fea0134b00a970f22f20f6d1dd"
          }
        },
        "80f6cea6a4394edb9f761e8a7859eaf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bd844c747d14740b765fba904b6c6f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f56cd22dbe5e49aba7fc705ac6fd39dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6f333fea0134b00a970f22f20f6d1dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "zy1NsLQ5YdvC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.base import BaseEstimator, ClassifierMixin\n",
        "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
        "from sklearn.utils.multiclass import unique_labels\n",
        "from typing import List\n",
        "from torchvision import models\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import time\n",
        "import sys"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjwZ0IXn8tG2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ecoc_classifier(ClassifierMixin, BaseEstimator):\n",
        "\n",
        "    def __init__(self, model_constructer=None, ecoc_matrix=None, model_list=None, code_word_length=0):\n",
        "        '''\n",
        "        there are two ways to use this class,\n",
        "        one is when there is already a function for defining blank models, which you can then simply supply using the model consuctre paramater\n",
        "        there other is when you want to supply a list of blank models your self which you can do with by using the model_list paramater\n",
        "\n",
        "        make sure to supply one or the other not both.\n",
        "\n",
        "        it is also nessary to supply a ecoc matrix, but unessary to supply a code length. (sklearn complains if any class variables don't have defualt values)\n",
        "\n",
        "        '''\n",
        "        self.model_constructer = model_constructer\n",
        "        self.ecoc_matrix = ecoc_matrix\n",
        "        self.model_list = model_list\n",
        "        self.code_word_length = code_word_length\n",
        "\n",
        "    def Hdistance(self, model_output : List , code_word : List ):# determins hamming distance\n",
        "\n",
        "        '''\n",
        "        counts the  diffrance in bits\n",
        "        '''\n",
        "\n",
        "        distance = 0\n",
        "        pos = 0\n",
        "        while(pos < self.code_word_length):\n",
        "\n",
        "            if( int(model_output[pos]) !=  code_word[pos] ):\n",
        "\n",
        "                distance += 1\n",
        "\n",
        "            pos += 1\n",
        "\n",
        "        return distance\n",
        "\n",
        "    def determinLable(self, results):\n",
        "\n",
        "        '''\n",
        "        when given an list of output codes from the models, this assigns a list\n",
        "        of code words from the ecoc matrix which are the smallest hamming distance\n",
        "        '''\n",
        "\n",
        "        output = np.empty( ( results.shape[0], self.code_word_length ) )\n",
        "\n",
        "        item = 0\n",
        "        while(item < results.shape[0]):\n",
        "\n",
        "            smallest_distance = -1\n",
        "\n",
        "            for code_word in self.ecoc_matrix :\n",
        "\n",
        "                distance = self.Hdistance(results[item], code_word)\n",
        "\n",
        "                if( distance < smallest_distance or smallest_distance == -1):\n",
        "\n",
        "                    smallest_distance = distance\n",
        "                    output_code = code_word\n",
        "\n",
        "            output[item] = np.array(output_code, copy=True)\n",
        "            item += 1\n",
        "\n",
        "        return output\n",
        "\n",
        "    def fit(self, X, y, **kwargs):\n",
        "\n",
        "        self.code_word_length = len(self.ecoc_matrix[0])\n",
        "\n",
        "        '''\n",
        "        a standerd implementation of fit used by all sklearn models\n",
        "\n",
        "        in this case it initalzes a model for each column of the ecoc matrix,\n",
        "        and then calls fit to train it on the bits of the column. after wards the\n",
        "        model is append to a list for latter use\n",
        "        '''\n",
        "\n",
        "        self.classes_ = unique_labels(y)\n",
        "\n",
        "        self.X_ = X\n",
        "        self.y_ = y\n",
        "\n",
        "        if(self.model_list == None):\n",
        "\n",
        "            self.model_list = []\n",
        "\n",
        "            if(self.model_constructer != None):\n",
        "\n",
        "                bit_pos = 0\n",
        "                while(bit_pos < self.code_word_length):\n",
        "\n",
        "                    self.model_list.append(self.model_constructer())\n",
        "                    bit_pos += 1\n",
        "\n",
        "            kwargs['column'] = None\n",
        "\n",
        "            bit_pos = 0\n",
        "            while(bit_pos < self.code_word_length):\n",
        "\n",
        "                kwargs['column'] = bit_pos\n",
        "\n",
        "                columnBits = y[:, bit_pos]\n",
        "                self.model_list[bit_pos].fit(X, columnBits, **kwargs)\n",
        "                bit_pos += 1\n",
        "\n",
        "        # Return the classifier\n",
        "        return self\n",
        "\n",
        "    def predict(self, X, y=None):\n",
        "\n",
        "        '''\n",
        "        a standerd implementation of the predict function used by all sklearn models.\n",
        "\n",
        "        here after checking if the data is vailid it is feed into each model of the list, and a new output code\n",
        "        is made from the outputs which is then check against the ecoc matrix to see which row the new code word\n",
        "        is closest to.\n",
        "        '''\n",
        "\n",
        "        # Check is fit had been called\n",
        "        check_is_fitted(self, ['X_', 'y_'])\n",
        "\n",
        "        print('predicting')\n",
        "\n",
        "        results = np.empty((self.code_word_length,) + (X.shape[0],) + (1,))\n",
        "\n",
        "        pos = 0;\n",
        "        for model in self.model_list:\n",
        "\n",
        "            results[pos] = model.predict( X ).cpu().numpy()\n",
        "            pos += 1\n",
        "\n",
        "        results = results.reshape((self.code_word_length, X.shape[0])).T.round()\n",
        "\n",
        "        global output_array\n",
        "        output_array = results\n",
        "\n",
        "        return self.determinLable(results)\n",
        "\n",
        "    def score(self, X, y):\n",
        "        results = self.predict(X)\n",
        "        right = 0\n",
        "\n",
        "        pos = 0\n",
        "        for sample in results:\n",
        "\n",
        "            if (sample == y[pos]).all():\n",
        "\n",
        "                right += 1\n",
        "\n",
        "\n",
        "            pos += 1\n",
        "\n",
        "        return right/X.shape[0]"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m56Nxpy8YHKP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Main_Model(nn.Module):\n",
        "\n",
        "    device = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.device = torch.device(\"cuda\")\n",
        "        super(Main_Model,self).__init__()\n",
        "\n",
        "        eye = models.resnet18(pretrained=True)\n",
        "        eye.require_grad = False\n",
        "        eye_out = eye.fc.out_features\n",
        "        self.prams = nn.ModuleList([eye,\n",
        "                                    nn.Linear(eye_out,64),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(64,10),\n",
        "                                    nn.ReLU(),\n",
        "                                    nn.Linear(10,1),\n",
        "                                    ]).to(self.device)\n",
        "    def forward(self,x):\n",
        "\n",
        "        for mod in self.prams:\n",
        "            x = mod(x)\n",
        "        return x\n",
        "\n",
        "    def fit(self,X, y, batch_size, epochs, column):\n",
        "        self.prams.train(True)\n",
        "        train_set = torch.utils.data.TensorDataset(torch.tensor(X),torch.tensor(y))\n",
        "        train_set = torch.utils.data.DataLoader(train_set, batch_size=batch_size, shuffle=False)\n",
        "        optimizer = torch.optim.Adam(self.prams.parameters(), lr=0.0001)\n",
        "        lr_schedular = torch.optim.lr_scheduler.StepLR(optimizer, 5)\n",
        "        loss_fn = nn.BCEWithLogitsLoss(reduction='mean')\n",
        "        #loss_fn = nn.CrossEntropyLoss()\n",
        "        pos = 0\n",
        "        total_time = 0\n",
        "        while( pos < epochs):\n",
        "            start_time = time.time()\n",
        "            running_loss = 0\n",
        "            for image_batch, label_batch in iter(train_set):\n",
        "                image_batch, label_batch = image_batch.to(self.device), label_batch.to(self.device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                outputs = self(image_batch)\n",
        "                loss = loss_fn(torch.flatten(outputs),label_batch)\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                running_loss += loss\n",
        "\n",
        "            epoch_time = (time.time() - start_time)\n",
        "            print(\"-{}/{}\".format(pos+1,epochs),\"train time:\", epoch_time,\"loss total:\", running_loss.item())\n",
        "            accuracy = self.eval(test_images, test_lables, 500, column)\n",
        "            lr_schedular.step()\n",
        "            total_time += epoch_time\n",
        "\n",
        "            pos += 1\n",
        "\n",
        "        global accuracy_array\n",
        "        accuracy_array.append(accuracy)\n",
        "        global time_totals\n",
        "        time_totals.append(total_time)        \n",
        "\n",
        "    def predict(self,X):\n",
        "\n",
        "      X = torch.tensor(X, device=self.device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "          output = self(X)\n",
        "\n",
        "          return torch.sigmoid(output).round()\n",
        "\n",
        "    def eval(self,X, y, batch_size, column):\n",
        "        self.prams.train(False)\n",
        "        test_set = torch.utils.data.TensorDataset(torch.tensor(X),torch.tensor(y))\n",
        "        test_set = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False)\n",
        "        right = 0\n",
        "\n",
        "        for image_batch, label_batch in iter(test_set):\n",
        "            image_batch, label_batch = image_batch.to(self.device), label_batch.to(self.device)[:,column].unsqueeze(1)\n",
        "            output_batch = self.predict(image_batch)\n",
        "            right += (output_batch == label_batch).sum().item()\n",
        "            \n",
        "        after = (right/y.shape[0])\n",
        "        print(\"after: \", after)\n",
        "        return after\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37FXVTxny4pr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "general_file_name = \"2__2_70\"\n",
        "\n",
        "training_images = np.load(\"/content/drive/My Drive/{}/{}/train_images.npy\".format(general_file_name[0],general_file_name[3])).swapaxes(1,3).astype(np.float32)\n",
        "training_lables = np.load(\"/content/drive/My Drive/{}/{}/train_lables.npy\".format(general_file_name[0],general_file_name[3])).astype(np.float32)\n",
        "  \n",
        "test_images = np.load(\"/content/drive/My Drive/1/{}/test_images.npy\".format(general_file_name[3])).swapaxes(1,3).astype(np.float32)\n",
        "test_lables = np.load(\"/content/drive/My Drive/1/{}/test_lables.npy\".format(general_file_name[3])).astype(np.int64)\n",
        "\n",
        "ecoc_matrix = np.loadtxt(\"/content/drive/My Drive/10x10\", delimiter=',')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mjh5mhb74RC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "dd065ff4daaf4cd4a003ef79fc9c4bf1",
            "69c374f0f74541bba0ff4c937c6d2a54",
            "eee99ad8546946a2b422d0f04686c048",
            "b91bf300d51d4c3e9638690f680d1781",
            "80f6cea6a4394edb9f761e8a7859eaf4",
            "2bd844c747d14740b765fba904b6c6f1",
            "f56cd22dbe5e49aba7fc705ac6fd39dc",
            "b6f333fea0134b00a970f22f20f6d1dd"
          ]
        },
        "outputId": "aaa45b02-2444-4da7-bdae-afc76d083a9c"
      },
      "source": [
        "\n",
        "main_model = ecoc_classifier(Main_Model, ecoc_matrix=ecoc_matrix)\n",
        "\n",
        "batch_size = 64\n",
        "epochs=10\n",
        "\n",
        "output_array = []\n",
        "\n",
        "accuracy_array = []\n",
        "\n",
        "time_totals = []\n",
        "\n",
        "average_time = np.vectorize(lambda x : x/epochs)\n",
        "\n",
        "main_model.fit(training_images, training_lables, batch_size=batch_size, epochs=epochs)\n",
        "\n",
        "print(main_model.score(test_images, test_lables))\n",
        "\n",
        "np.save('/content/drive/My Drive/{}_accuracy_array'.format(general_file_name), np.array(accuracy_array))\n",
        "np.save('/content/drive/My Drive/{}_output_array'.format(general_file_name), output_array)\n",
        "np.save('/content/drive/My Drive/{}_total_times'.format(general_file_name), np.array(time_totals))\n",
        "np.save('/content/drive/My Drive/{}_average_times'.format(general_file_name), average_time(time_totals))\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd065ff4daaf4cd4a003ef79fc9c4bf1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "-1/10 train time: 12.949358940124512 loss total: 165.62554931640625\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "after:  0.87965\n",
            "-2/10 train time: 12.620193243026733 loss total: 129.66409301757812\n",
            "after:  0.8595\n",
            "-3/10 train time: 12.717659711837769 loss total: 100.82749938964844\n",
            "after:  0.8895\n",
            "-4/10 train time: 12.829458951950073 loss total: 82.33519744873047\n",
            "after:  0.9058\n",
            "-5/10 train time: 12.92966604232788 loss total: 65.42742919921875\n",
            "after:  0.90435\n",
            "-6/10 train time: 13.02116346359253 loss total: 37.933868408203125\n",
            "after:  0.93125\n",
            "-7/10 train time: 13.082579612731934 loss total: 23.136892318725586\n",
            "after:  0.9363\n",
            "-8/10 train time: 13.124674081802368 loss total: 13.883307456970215\n",
            "after:  0.9384\n",
            "-9/10 train time: 13.190455436706543 loss total: 7.977746486663818\n",
            "after:  0.9397\n",
            "-10/10 train time: 13.223674535751343 loss total: 4.820738792419434\n",
            "after:  0.939\n",
            "-1/10 train time: 13.64333438873291 loss total: 189.74867248535156\n",
            "after:  0.86695\n",
            "-2/10 train time: 13.570057392120361 loss total: 140.33636474609375\n",
            "after:  0.87115\n",
            "-3/10 train time: 13.604450941085815 loss total: 110.44784545898438\n",
            "after:  0.88275\n",
            "-4/10 train time: 13.641519784927368 loss total: 89.01873016357422\n",
            "after:  0.90015\n",
            "-5/10 train time: 13.67356252670288 loss total: 72.87232971191406\n",
            "after:  0.8835\n",
            "-6/10 train time: 13.707193613052368 loss total: 39.745086669921875\n",
            "after:  0.9239\n",
            "-7/10 train time: 13.708008050918579 loss total: 23.073740005493164\n",
            "after:  0.9287\n",
            "-8/10 train time: 13.724423885345459 loss total: 13.023856163024902\n",
            "after:  0.93135\n",
            "-9/10 train time: 13.711114406585693 loss total: 6.65726375579834\n",
            "after:  0.93255\n",
            "-10/10 train time: 13.696013927459717 loss total: 3.884733200073242\n",
            "after:  0.931\n",
            "-1/10 train time: 13.963719367980957 loss total: 113.45165252685547\n",
            "after:  0.9379\n",
            "-2/10 train time: 13.839850664138794 loss total: 75.71937561035156\n",
            "after:  0.92895\n",
            "-3/10 train time: 13.862080574035645 loss total: 53.28525924682617\n",
            "after:  0.92255\n",
            "-4/10 train time: 13.866085529327393 loss total: 43.62089157104492\n",
            "after:  0.95645\n",
            "-5/10 train time: 13.854201316833496 loss total: 33.786685943603516\n",
            "after:  0.9329\n",
            "-6/10 train time: 13.82424545288086 loss total: 13.168505668640137\n",
            "after:  0.96715\n",
            "-7/10 train time: 13.808329582214355 loss total: 6.415538311004639\n",
            "after:  0.96945\n",
            "-8/10 train time: 13.788766384124756 loss total: 3.0493645668029785\n",
            "after:  0.9702\n",
            "-9/10 train time: 13.768199920654297 loss total: 1.5854363441467285\n",
            "after:  0.96965\n",
            "-10/10 train time: 13.759333848953247 loss total: 0.7616861462593079\n",
            "after:  0.9704\n",
            "-1/10 train time: 13.964879751205444 loss total: 200.79049682617188\n",
            "after:  0.8713\n",
            "-2/10 train time: 13.832238674163818 loss total: 142.28021240234375\n",
            "after:  0.87705\n",
            "-3/10 train time: 13.819845199584961 loss total: 105.60697937011719\n",
            "after:  0.87145\n",
            "-4/10 train time: 13.81111764907837 loss total: 83.6202392578125\n",
            "after:  0.8824\n",
            "-5/10 train time: 13.812776565551758 loss total: 67.02125549316406\n",
            "after:  0.8698\n",
            "-6/10 train time: 13.794617176055908 loss total: 30.12247657775879\n",
            "after:  0.9306\n",
            "-7/10 train time: 13.760331869125366 loss total: 16.19186782836914\n",
            "after:  0.9338\n",
            "-8/10 train time: 13.72304654121399 loss total: 9.145654678344727\n",
            "after:  0.93515\n",
            "-9/10 train time: 13.686276912689209 loss total: 4.864467144012451\n",
            "after:  0.9362\n",
            "-10/10 train time: 13.661284446716309 loss total: 2.7413089275360107\n",
            "after:  0.93615\n",
            "-1/10 train time: 13.992851734161377 loss total: 224.36544799804688\n",
            "after:  0.8354\n",
            "-2/10 train time: 13.857993364334106 loss total: 171.75587463378906\n",
            "after:  0.84095\n",
            "-3/10 train time: 13.847628116607666 loss total: 136.29244995117188\n",
            "after:  0.84205\n",
            "-4/10 train time: 13.856638431549072 loss total: 108.62959289550781\n",
            "after:  0.859\n",
            "-5/10 train time: 13.846987247467041 loss total: 94.20304870605469\n",
            "after:  0.85065\n",
            "-6/10 train time: 13.860207557678223 loss total: 53.47868347167969\n",
            "after:  0.9099\n",
            "-7/10 train time: 13.8413245677948 loss total: 33.51356506347656\n",
            "after:  0.9143\n",
            "-8/10 train time: 13.829505443572998 loss total: 21.13182258605957\n",
            "after:  0.91855\n",
            "-9/10 train time: 13.817980766296387 loss total: 12.16968822479248\n",
            "after:  0.9212\n",
            "-10/10 train time: 13.804231405258179 loss total: 6.803302764892578\n",
            "after:  0.9225\n",
            "-1/10 train time: 14.02884292602539 loss total: 225.528564453125\n",
            "after:  0.83945\n",
            "-2/10 train time: 13.866141319274902 loss total: 169.54580688476562\n",
            "after:  0.83715\n",
            "-3/10 train time: 13.850667715072632 loss total: 131.13536071777344\n",
            "after:  0.8582\n",
            "-4/10 train time: 13.856550693511963 loss total: 103.23406982421875\n",
            "after:  0.86735\n",
            "-5/10 train time: 13.827894687652588 loss total: 84.81293487548828\n",
            "after:  0.8772\n",
            "-6/10 train time: 13.820920944213867 loss total: 49.01680374145508\n",
            "after:  0.9076\n",
            "-7/10 train time: 13.815023183822632 loss total: 29.727447509765625\n",
            "after:  0.91495\n",
            "-8/10 train time: 13.80933141708374 loss total: 17.837268829345703\n",
            "after:  0.9185\n",
            "-9/10 train time: 13.801595211029053 loss total: 9.596590995788574\n",
            "after:  0.9215\n",
            "-10/10 train time: 13.803957462310791 loss total: 5.067188262939453\n",
            "after:  0.92135\n",
            "-1/10 train time: 13.974901914596558 loss total: 199.3993377685547\n",
            "after:  0.8714\n",
            "-2/10 train time: 13.84221625328064 loss total: 135.03347778320312\n",
            "after:  0.88215\n",
            "-3/10 train time: 13.824142456054688 loss total: 101.16903686523438\n",
            "after:  0.8829\n",
            "-4/10 train time: 13.825083017349243 loss total: 76.94524383544922\n",
            "after:  0.9075\n",
            "-5/10 train time: 13.810229539871216 loss total: 62.01367950439453\n",
            "after:  0.92055\n",
            "-6/10 train time: 13.809471130371094 loss total: 27.62076759338379\n",
            "after:  0.936\n",
            "-7/10 train time: 13.803475856781006 loss total: 13.496248245239258\n",
            "after:  0.939\n",
            "-8/10 train time: 13.77606463432312 loss total: 6.560746192932129\n",
            "after:  0.9402\n",
            "-9/10 train time: 13.757069110870361 loss total: 2.7662692070007324\n",
            "after:  0.94095\n",
            "-10/10 train time: 13.741822242736816 loss total: 2.135281562805176\n",
            "after:  0.93875\n",
            "-1/10 train time: 14.003008604049683 loss total: 194.77854919433594\n",
            "after:  0.8728\n",
            "-2/10 train time: 13.858524560928345 loss total: 136.9925079345703\n",
            "after:  0.88365\n",
            "-3/10 train time: 13.85515546798706 loss total: 104.41426086425781\n",
            "after:  0.885\n",
            "-4/10 train time: 13.859969854354858 loss total: 77.85089874267578\n",
            "after:  0.8784\n",
            "-5/10 train time: 13.850767850875854 loss total: 68.58979797363281\n",
            "after:  0.87085\n",
            "-6/10 train time: 13.872211933135986 loss total: 35.82762908935547\n",
            "after:  0.9324\n",
            "-7/10 train time: 13.849112033843994 loss total: 20.019546508789062\n",
            "after:  0.9359\n",
            "-8/10 train time: 13.819621086120605 loss total: 10.78422737121582\n",
            "after:  0.9385\n",
            "-9/10 train time: 13.774975538253784 loss total: 4.995248317718506\n",
            "after:  0.93915\n",
            "-10/10 train time: 13.73278546333313 loss total: 1.9001528024673462\n",
            "after:  0.9394\n",
            "-1/10 train time: 14.037307977676392 loss total: 220.04319763183594\n",
            "after:  0.8349\n",
            "-2/10 train time: 13.879040002822876 loss total: 170.35426330566406\n",
            "after:  0.8371\n",
            "-3/10 train time: 13.874488592147827 loss total: 135.61505126953125\n",
            "after:  0.83395\n",
            "-4/10 train time: 13.876027345657349 loss total: 107.00535583496094\n",
            "after:  0.86575\n",
            "-5/10 train time: 13.871293544769287 loss total: 88.63949584960938\n",
            "after:  0.8677\n",
            "-6/10 train time: 13.869173288345337 loss total: 49.357994079589844\n",
            "after:  0.90885\n",
            "-7/10 train time: 13.875596284866333 loss total: 29.36460304260254\n",
            "after:  0.91295\n",
            "-8/10 train time: 13.876364707946777 loss total: 17.278606414794922\n",
            "after:  0.9153\n",
            "-9/10 train time: 13.867141246795654 loss total: 9.176118850708008\n",
            "after:  0.9189\n",
            "-10/10 train time: 13.853164911270142 loss total: 5.340026378631592\n",
            "after:  0.9185\n",
            "-1/10 train time: 14.02746295928955 loss total: 227.46420288085938\n",
            "after:  0.8357\n",
            "-2/10 train time: 13.878580093383789 loss total: 168.1733856201172\n",
            "after:  0.83995\n",
            "-3/10 train time: 13.877190589904785 loss total: 132.51025390625\n",
            "after:  0.86545\n",
            "-4/10 train time: 13.871782541275024 loss total: 106.74406433105469\n",
            "after:  0.8769\n",
            "-5/10 train time: 13.857255458831787 loss total: 85.38908386230469\n",
            "after:  0.8766\n",
            "-6/10 train time: 13.8501296043396 loss total: 47.418548583984375\n",
            "after:  0.90535\n",
            "-7/10 train time: 13.842504024505615 loss total: 29.035062789916992\n",
            "after:  0.91445\n",
            "-8/10 train time: 13.825767278671265 loss total: 16.91642189025879\n",
            "after:  0.91795\n",
            "-9/10 train time: 13.809158563613892 loss total: 9.634551048278809\n",
            "after:  0.9191\n",
            "-10/10 train time: 13.767704248428345 loss total: 5.30009651184082\n",
            "after:  0.91915\n",
            "predicting\n",
            "0.8829\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}